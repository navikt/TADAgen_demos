{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# scikit-learn model cards\n",
    "\n",
    "This guide demonstrates how you can use this package to create a model card on a\n",
    "scikit-learn compatible model and save it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "First we will import everything required for the rest of this document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp, mkstemp\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import HalvingGridSearchCV, train_test_split\n",
    "\n",
    "from skops import hub_utils\n",
    "from skops.card import Card, metadata_from_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "We load breast cancer dataset from sklearn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "print(\"X's summary: \", X.describe())\n",
    "print(\"y's summary: \", y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model\n",
    "Using the above data, we train a model. To select the model, we use\n",
    ":class:`~sklearn.model_selection.HalvingGridSearchCV` with a parameter grid\n",
    "over :class:`~sklearn.ensemble.HistGradientBoostingClassifier`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_leaf_nodes\": [5, 10, 15],\n",
    "    \"max_depth\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "model = HalvingGridSearchCV(\n",
    "    estimator=HistGradientBoostingClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ").fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a repository to save our files in\n",
    "We will now initialize a repository and save our model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ''.join(random.choices(string.ascii_lowercase +\n",
    "                             string.digits, k=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "local_repo = 'models/skops-'+f'{model_name}'\n",
    "os.mkdir(f'{local_repo}')\n",
    "\n",
    "pkl_name = 'models/skops-'+f'{model_name}'+'.pkl'\n",
    "\n",
    "with open(pkl_name, mode=\"bw\") as f:\n",
    "    pickle.dump(model, file=f)\n",
    "\n",
    "hub_utils.init(\n",
    "    model=pkl_name,\n",
    "    requirements=[f\"scikit-learn={sklearn.__version__}\"],\n",
    "    dst=local_repo,\n",
    "    task=\"tabular-classification\",\n",
    "    data=X_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model card\n",
    "We now create a model card, and populate its metadata with information which\n",
    "is already provided in ``config.json``, which itself is created by the call to\n",
    ":func:`.hub_utils.init` above. We will see below how we can populate the model\n",
    "card with useful information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_card = Card(model, metadata=metadata_from_config(Path(local_repo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more information\n",
    "So far, the model card does not tell viewers a lot about the model. Therefore,\n",
    "we add more information about the model, like a description and what its\n",
    "license is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_card.metadata.license = \"mit\"\n",
    "limitations = \"This model is not ready to be used in production.\"\n",
    "model_description = (\n",
    "    \"This is a `HistGradientBoostingClassifier` model trained on breast cancer \"\n",
    "    \"dataset. It's trained with `HalvingGridSearchCV`, with parameter grids on \"\n",
    "    \"`max_leaf_nodes` and `max_depth`.\"\n",
    ")\n",
    "model_card_authors = \"skops_user\"\n",
    "citation_bibtex = \"**BibTeX**\\n\\n```\\n@inproceedings{...,year={2020}}\\n```\"\n",
    "model_card.add(\n",
    "    **{\n",
    "        \"Citation\": citation_bibtex,\n",
    "        \"Model Card Authors\": model_card_authors,\n",
    "        \"Model description\": model_description,\n",
    "        \"Model description/Intended uses & limitations\": limitations,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add plots, metrics, and tables to our model card\n",
    "Furthermore, to better understand the model performance, we should evaluate it\n",
    "on certain metrics and add those evaluations to the model card. In this\n",
    "particular example, we want to calculate the accuracy and the F1 score. We\n",
    "calculate those using sklearn and then add them to the model card by calling\n",
    ":meth:`.Card.add_metrics`. But this is not all, we can also add matplotlib\n",
    "figures to the model card, e.g. a plot of the confusion matrix. To achieve\n",
    "this, we create the plot using sklearn, save it locally, and then add it using\n",
    ":meth:`.Card.add_plot` method. Finally, we can also add some useful tables to\n",
    "the model card, e.g. the results from the grid search and the classification\n",
    "report. Those can be added using :meth:`.Card.add_table`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "eval_descr = (\n",
    "    \"The model is evaluated on test data using accuracy and F1-score with \"\n",
    "    \"macro average.\"\n",
    ")\n",
    "model_card.add(**{\"Model description/Evaluation Results\": eval_descr})\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "model_card.add_metrics(**{\"accuracy\": accuracy, \"f1 score\": f1})\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "disp.figure_.savefig(Path(local_repo) / \"confusion_matrix.png\")\n",
    "model_card.add_plot(\n",
    "    **{\"Model description/Evaluation Results/Confusion Matrix\": \"confusion_matrix.png\"}\n",
    ")\n",
    "\n",
    "cv_results = model.cv_results_\n",
    "clf_report = classification_report(\n",
    "    y_test, y_pred, output_dict=True, target_names=[\"malignant\", \"benign\"]\n",
    ")\n",
    "# The classification report has to be transformed into a DataFrame first to have\n",
    "# the correct format. This requires removing the \"accuracy\", which was added\n",
    "# above anyway.\n",
    "del clf_report[\"accuracy\"]\n",
    "clf_report = pd.DataFrame(clf_report).T.reset_index()\n",
    "model_card.add_table(\n",
    "    folded=True,\n",
    "    **{\n",
    "        \"Model description/Evaluation Results/Hyperparameter search results\": cv_results,\n",
    "        \"Model description/Evaluation Results/Classification report\": clf_report,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model card\n",
    "We can simply save our model card by providing a path to :meth:`.Card.save`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_card.save(Path(local_repo)/\"README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_card.save(Path(f\"{local_path}/README.md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
